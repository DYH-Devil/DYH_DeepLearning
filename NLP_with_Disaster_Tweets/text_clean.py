"""
The target of this page:æ¸…æ´—æ–‡æœ¬æ•°æ®ï¼Œå»é™¤ä¸å¿…è¦çš„ç¬¦å·ï¼Œè¡¨æƒ…ç­‰
"""
import re
from get_data import text_train , text_test
from torchtext.data.utils import get_tokenizer#åˆ†è¯å™¨
from string import punctuation as punctuation_string

#----------------------------------------------------------------------------------------------
#step1:å»é™¤è¡¨æƒ…ç¬¦å·
def clean_emoji(text) :
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'EMOJI', text)

# #test:
# text = 'hellow I name is ğŸ˜€'
# text = clean_emoji(text)
# res:hellow I name is EMOJI
# print(text)
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step2:å»é™¤å¼•ç”¨ç¬¦@ä»¥åŠåé¢çš„ç”¨æˆ·å
def clean_at(text) :
    at = re.compile(r'@\S+')
    return at.sub(r'username', text)#å°†@åçš„ç”¨æˆ·åç”¨usernameæ›¿æ¢

# #test
# text = 'please @DYHBadBoy thank U!'
# print(clean_at(text))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step3:å»é™¤HTMLæ ‡è®°å†…å®¹
def clean_HTML(text) :
    html = re.compile(r'<.*?>')
    return html.sub(r'' , text)

# #test
# text = """<div>
# <h1>Real or Fake</h1>
# <p>Kaggle </p>
# <a href="https://www.kaggle.com/c/nlp-getting-started">getting started</a>
# </div>"""
# print(clean_HTML(text))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step4:å»é™¤urlé“¾æ¥
def cleam_URL(text) :
    url = re.compile(r'https?://\S+|www\.\S+')
    return url.sub(r'URL', text)

# #test
# text = 'Coucou, venez sur https://www.youtube.com/'
# print(cleam_URL(text))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step5:å»é™¤é‡å¤çš„æ ‡ç‚¹ç¬¦å·
def clean_repeat_punct(text) :
    rep = re.compile(r'([!?.,]){2,}')
    return rep.sub(r'\1 REPEAT', text)

# #test
# print(clean_repeat_punct(",,,,,,,"))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step6:å»é™¤å•è¯åæ‹–é•¿çš„å­—ç¬¦ï¼Œå¦‚:yessssss,okkkkkk
def clean_words_elong(text) :
    rep = re.compile(r'\b(\S*?)([a-z])\2{2,}\b')
    return rep.sub(r'\1\2 ELONG', text)

# #test
# text = 'yesssss okkkkkk'
# print(clean_words_elong(text))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step7:å»é™¤æ•°å­—
def clean_number(text):
    rep = re.compile(r'[-+]?[.\d]*[\d]+[:,.\d]*')
    return rep.sub('', text)

# #test
# print(clean_number("13.5"))
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#step7:å»é™¤æ ‡ç‚¹
def clean_punctuation(text):
    rep = re.sub('[{}]'.format(punctuation_string),"",text)
    return rep

# #test
# print(clean_number("13.5"))
#----------------------------------------------------------------------------------------------

#END

def text_process(text_list) :
    text_process = []
    for text in text_list :
        text = text.lower()#è½¬å°å†™
        text = clean_emoji(text)
        text = clean_at(text)
        text = clean_HTML(text)
        text = cleam_URL(text)
        text = clean_repeat_punct(text)
        text = clean_words_elong(text)
        text = clean_number(text)
        text = clean_punctuation(text)
        text_process.append(text)
    return text_process

def split_word(text) :#æ–‡æœ¬åˆ†è¯
    tokenizer = get_tokenizer('basic_english')
    word_split = []
    for line in text :
        word_split.append(tokenizer(line))#å¯¹æ¯æ¡æ¨æ–‡è¿›è¡Œåˆ†è¯
    return word_split

